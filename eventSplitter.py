import pandas as pd
import random
import time
import os
import subprocess
import numpy as np
from statistics_counters import get_raw_split_annotations

MAIN_VID_PATH = "Video/"
MAIN_ANN_PATH = "/home/sami/Work/resources/inter-rater/"
MAIN_OUT_VID_PATH = "ExampleOut/"
FOLDER_CHAR = "/"
FFMPEG_COMMAND = "ffmpeg"
ALL_FILES_CSV = "all_filesFeb27.csv"
CODEC = "copy"  ## if there is no nvidia GPU, replace this with the CPU Powered 'libx264', or even faster, skip encoding with 'copy'




def split_and_save(rootdir, orig, start, duration, name):  ## **DONE**
    """
    runs command line commands to FFMPEG to clip a video

    arguments:
        rootdir (str): the directory to navigate to, usually whatever allows us to access the video in the 'orig' variable
        orig (str): full path or name of the video to copy from
        start (int/float): start time of clip, in seconds
        duration (int/float): duration of clip, in seconds
        name (str): full path or name of video to be saved

    returns:
        nothing, but the command it runs will create a new video wherever 'name' is, depending on where the function navigated with using 'rootdir'
    """
    subprocess.run(
        [
            FFMPEG_COMMAND,  ## make this point to where ffmpeg is, or if FFMPEG is in PATH then just replace this with FFMPEG
            "-i",
            orig,
            "-ss",
            start,
            "-t",
            duration,
            "-c:v",  ## signifies that we are rencoding video
            CODEC,
            "-qp",
            "16",  ## higher means less quality and lower file size. inverse is true
            rootdir + name,
        ]
    )


def import_data_durations(file_name):  ## **DONE**
    """
    This is the main function to import duration data.  
    
    Cycles through a text file and saves start times and duration in key and dictionary, respectively

    arguments:
        file_name (str): path to the text file

    returns:
        annotation_data (df): a data frame indexed by type of engagment, which contains start and duration stats
    """
    annotation_data = pd.read_csv(
        file_name, "\t", header=None, usecols=[0, 5, 2, 4, 3]
    ).set_index([0, 5])
    try:
        annotation_data = annotation_data.drop(index="default", level=0)
    except:
        pass
    end_time = annotation_data[3].describe().max()
    return annotation_data, end_time


def import_paths_from_txt(txt):  ## **DONE**
    """
    borrowed from data counter, imports lines as elements of a list.

    allows us to store paths in persistent .txt file, and just pull from that

    arguments:
        txt (str): path to text file with paths

    returns:
        out (list): list where elements are paths
    """

    out = pd.read_csv(txt, header=None).values.flatten().tolist()
    return out


def clean_cuts(ms_data, window):  ## NOTE: brand new, merging of two functions
    """
    merge of clean_cuts_percentages and clean_cuts_status.  Output is changed between the two using the 'kind' string

    arguments:
        ms_data (df): data from import_data_ms
        window (int): size of the calculation window, in milliseconds
        ~~kind (str): '%' if you want percentages, 'bool' if you want status (True/False)~~ THIS IS DEPRECATED, USE GET_RAW_SPLITS FOR BOOL
    """
    previndex = 0
    output = pd.DataFrame(
        columns=[
            "sequence",
            "on-task",
            "off-task",
            "satisfied",
            "confused",
            "bored",
            "focused",
            "idle",
            "distracted",
        ]
    ).set_index("sequence")
    seq = 0
    for i in range(len(ms_data) + 2):
        if i == 0:
            continue
        if i % window == 0:
            seq += 1
            data = get_percentages(ms_data, window, previndex, i)
            previndex = i
            output.loc[seq] = data.loc[0].tolist()
    return output


def import_data_ms(file_name):  ## **DONE**
    '''
    This is the main function to import duration data but IN MILLISECONDS

    Uses the dataframe generated by import_data_duration to populate a dataframe where tag values are indexed to the millisecond

    Important for clean_cuts and associaton_splitter
    
    arguments:
        file_name (str): path to the text file

    returns:
        ms_data (df): a data frame indexed by millisecond, relating to the value of each tag
    '''
    annotation_data, endtime = import_data_durations(file_name)
    tags = [
        "on-task",
        "off-tsak",
        "Bored",
        "Confused",
        "Satisfied",
        "distarcted",
        "idle",
        "focused",
    ]
    tagsMapped = {
        "on-task": (2, "behavior"),
        "off-tsak": (1, "behavior"),
        "Bored": (1, "emotion"),
        "Confused": (2, "emotion"),
        "Satisfied": (3, "emotion"),
        "distarcted": (1, "attention"),
        "idle": (2, "attention"),
        "focused": (3,"attention")
    }
    ms_data = pd.DataFrame(
        0,
        index=(np.arange(int(endtime * 1000))),
        columns=["behavior", "attention", "emotion"],
    )
    for tag in tags:
        try:
            times = annotation_data.xs(tag, level=1).iterrows()
        except:
            continue
        for elem in times:
            start = int(1000 * (elem[1][2]))
            stop = int(1000 * (elem[1][2] + elem[1][4]))
            label = tagsMapped[tag][1]
            val = tagsMapped[tag][0]
            ms_data.loc[start:stop, label] = val

    return ms_data


def get_percentages(df, window, previndex, i): ## **DONE**
    """
    used in clean_cuts to get percentages per window.

    arguments:
        all arguments are inherited from clean_cuts
    """
    behaviorCounts = df[previndex:i]["behavior"].value_counts()
    attentionCounts = df[previndex:i]["attention"].value_counts()
    emotionCounts = df[previndex:i]["emotion"].value_counts()
    percentageDF = pd.DataFrame(
        columns=[
            "on-task",
            "off-task",
            "satisfied",
            "confused",
            "bored",
            "focused",
            "idle",
            "distracted",
        ]
    )
    percentageDF.loc[0] = [0, 0, 0, 0, 0, 0, 0, 0]
    for item in behaviorCounts.iteritems():
        if item[0] == 1:
            percentageDF.loc[0]["off-task"] = item[1] / window
        elif item[0] == 2:
            percentageDF.loc[0]["on-task"] = item[1] / window
    for item in attentionCounts.iteritems():
        if item[0] == 1:
            percentageDF.loc[0]["distracted"] = item[1] / window
        elif item[0] == 2:
            percentageDF.loc[0]["idle"] = item[1] / window
        elif item[0] == 3:
            percentageDF.loc[0]["focused"] = item[1] / window
    for item in emotionCounts.iteritems():
        if item[0] == 1:
            percentageDF.loc[0]["bored"] = item[1] / window
        elif item[0] == 2:
            percentageDF.loc[0]["confused"] = item[1] / window
        elif item[0] == 3:
            percentageDF.loc[0]["satisfied"] = item[1] / window

    return percentageDF


def getVideoPath(textPath, locations, extras=False): ## **DONE**
    file_name_splits = os.path.basename(textPath).split(".")[0].split("_")
    p = file_name_splits[0]
    s = file_name_splits[1]
    csv = pd.read_csv(locations, header=None, usecols=[0, 1, 2]).set_index([0, 1])
    vid_folder = csv.xs([p, s]).to_list()[0]
    full_path = MAIN_VID_PATH + p + FOLDER_CHAR + s + FOLDER_CHAR + vid_folder
    found = False
    for file in os.listdir(full_path):
        if file.endswith(".mp4") and file.startswith(p + "_" + s):
            path = os.path.join(full_path, file)
            found = True
            if extras:
                return (path,p,s,)  
            return path
    if not found:
        print("Video file does not exsist")
        return ""
        # raise Exception('Video file does not exsist')


def numbered_splitter(start, duration,window, p, s, tag, vPath, char, number, event = False): ## **DONE**
    if event:
        name = (
            p
            + "_"
            + s
            + "_"
            + 'event'
            + "_"
            + tag
            + "_B"
            + str(round(start, 3))
            + "_"
            + str(window)
            + "s.mp4"
        )
    elif not event:
        name = (
            p
            + "_"
            + s
            + "_"
            + "non_event"
            + "_"
            + tag
            + "_S"
            + str(round(start, 3))
            + "_"
            + char
            + str(number)
            + "_"
            + str(window)
            + "s.mp4"
        )
    split_and_save(MAIN_OUT_VID_PATH, vPath, str(start), str(window), name)
 
def data_prep(splits):
    output = {}
    annotation_label = ['on-task', 'off-tsak', 'Satisfied', 'Confused', 'Bored', 'focused', 'idle', 'distarcted']
    splits_temp = splits.fillna(False).reset_index(drop=False).set_index(annotation_label)
    try:
        NSF = splits_temp.xs([True, False, True, False, False, True, False, False])
        output['NSF'] = NSF
    except:
        print('No NSF associations')
    try:
        FSF = splits_temp.xs([False, True, True, False, False, True, False, False])
        output['FSF'] = FSF
    except:
        print('No FSF associations')
    try:
        FBI = splits_temp.xs([False, True,False,False,True,False,True,False])
        output['FBI'] = FBI
    except:
        print("No FBI associations")
    try:
        FBD = splits_temp.xs([False, True,False,False,True,False,False,True])
        output['FBD'] = FBD
    except:
        print("No FBD associations")
    
    behaviorSplits = splits.fillna(False).drop(columns=['Satisfied', 'Confused', 'Bored', 'focused', 'idle', 'distarcted']).reset_index(drop=False).set_index(['on-task','off-tsak'])
    emotionSplits = splits.fillna(False).drop(columns=['focused', 'idle', 'distarcted','on-task','off-tsak']).reset_index(drop=False).set_index(['Satisfied','Confused','Bored'])
    attentionSplits = splits.fillna(False).drop(columns=['Satisfied', 'Confused', 'Bored', 'on-task', 'off-tsak']).reset_index(drop=False).set_index(['focused','idle','distarcted'])
    
    try:
        onTask = behaviorSplits.xs([True,False])
        output['on-task'] = onTask
    except:
        print('THERE ARE NO ON-TASK TAGS. THIS IS UNUSUAL, but is not a cause for concern')
    try:
        offTask = behaviorSplits.xs([False, True])
        output['off-task'] = offTask
    except:
        print('THERE ARE NO OFF-TASK TAGS. THIS IS UNUSUAL, but is not a cause for concern')
    try:
        satisfied = emotionSplits.xs([True, False, False])
        output['satisfied'] = satisfied
    except:
        print("THERE ARE NO SATISFIED TAGS. THIS IS UNUSUAL, but is not a cause for concern")
    try:
        confused = emotionSplits.xs([False, True, False])
        output['confused'] = confused
    except:
        print("THERE ARE NO CONFUSED TAGS. THIS IS UNUSUAL, but is not a cause for concern.")
    try:
        bored = emotionSplits.xs([False, False, True])
        output['bored'] = bored
    except:
        print("THERE ARE NO BORED TAGS. THIS IS UNUSUAL, but is not a cause for concern")
    try:
        focused = attentionSplits.xs([True, False, False])
        output['focused'] = focused
    except:
        print("THERE ARE NO FOCUSED TAGS. THIS IS UNUSUAL, but is not a cause for concern")
    try:
        idle = attentionSplits.xs([False,True,False])
        output['idle'] = idle
    except:
        print("THERE ARE NO IDLE TAGS. THIS IS UNUSUAL, but is not a cause for concern")
    try:
        distracted = attentionSplits.xs([False,False,True])
        output['distracted'] = distracted
    except:
        print("THERE ARE NO DISTRACTED TAGS. THIS IS UNUSUAL, but is not a cause for concern")\

    return output

def splitting_categories(category_name, category_array,window,p,s, vPath, char):
    number = 0
    for index, row in category_array.iterrows():
        # print(row[0],row[1])
        start = row[0]
        duration = row[1] - start
        number += 1
        numbered_splitter(start,duration,window,p,s, category_name,vPath,char,number)

if __name__ == "__main__":
    paths = import_paths_from_txt("paths.txt")
    # passes = 100
    # random_paths = random.choices(paths, k=passes)
    path = MAIN_ANN_PATH + paths[0]
    data = import_data_durations(path)[0]
    splits = get_raw_split_annotations(data,3)
    vPath, p, s = getVideoPath(path,ALL_FILES_CSV,True)
    annotation_label = ['on-task', 'off-tsak', 'Satisfied', 'Confused', 'Bored', 'focused', 'idle', 'distarcted']
    splits_temp = splits.reset_index(drop=False).set_index(annotation_label)
    # NSF = splits_temp.xs([True, False, True, False, False, True, False, False])
    
    # onTask = splits.drop(columns=['Satisfied', 'Confused', 'Bored', 'focused', 'idle', 'distarcted'])
    # splits_temp = splits.reset_index(drop=False).set_index(annotation_label)
    # onTask = onTask.reset_index(drop=False).set_index(['on-task','off-tsak'])
    # onTask = onTask.xs([True,False])
    # print(splits.fillna(False))
    dic = data_prep(splits)
    print(dic['on-task'])
    #same to other categories 
    # FSF = splits_temp.xs(labels)
    #this way you don't need the 'prev' var and the loop will be faster (no need to check each row)
    #this could be a function so you don't repeat the code every time and in case you need to edit, you will not need to edit each one and 
    # spliting_categories("on-task", onTask, 3, p, s, vPath)
    # print(onTask)

    